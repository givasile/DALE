Recently, Machine Learning (ML) models have flourished in critical, high-stakes application domains, such as healthcare and finance. These fields require methods with the ability to explain their predictions, i.e., justify why a specific outcome has emerged. However, several types of accurate and highly non-linear models like Deep Neural Networks do not meet this requirement. Therefore, there is a growing need for explainability methods for interpreting such ``black-box'' models.

Feature effect forms a fundamental category of global explainability methods (i.e. characterizing the model as a whole, not a particular input). The goal of the feature effect is to isolate the average impact of a single feature on the output. This class of methods is attractive due to the simplicity of the explanation that is easily understandable by a non-expert.

There are three popular feature effect methods: (i) Partial Dependence Plots (PDPlots)~\cite{Friedman2001}, (ii) Marginal Plots (MPlots)~\cite{Apley2020} and (iii) Aggregated Local Effects (ALE)~\cite{Apley2020}. PDPlots and MPlots assume that input features are not correlated. When this does not hold, both methods perform poorly; PDPlots quantify the effect by marginalizing over out-of-distribution synthetic instances (OOD), and MPlots attribute aggregated effects on single features. Therefore, both methods perform well only in the case of independent or low-correlated features. ALE is the only feature effect method that succeeds in staying on distribution and isolating feature effects in typical ML scenarios where input features are highly-correlated\footnote{In Section~\ref{sec:3-feature-effect}, we provide a thorough analysis for clarifying the differences between these three approaches.}.

In most cases, it is impossible to compute ALE through its definition since this would require (a) solving a high-dimensional integral, which is infeasible, and (b) evaluating the data generating distribution, which is usually unknown. Therefore, the original ALE paper~\cite{Apley2020} proposed a Monte-Carlo approximation, which faces two weaknesses. First, it becomes computationally inefficient in cases of datasets with numerous high-dimensional instances. Second, it is still vulnerable to OOD sampling in cases of wide bin sizes.

This paper proposes Differential Aggregated Local Effects (DALE), a novel approximation for ALE that resolves both weaknesses. DALE leverages auto-differentiation for computing the derivatives wrt each instance in a single pass. Therefore, it scales well in the case of high-dimensional inputs, large training sets and expensive black-box models. Furthermore, DALE estimates the feature effect using only the examples from the training set, securing that the estimation is not affected by OOD samples.
%
The contributions of this work are:
%
\begin{itemize}
\item We introduce DALE, a novel approximation to efficiently create ALE plots on differentiable black-box models. DALE is more efficient than the traditional ALE approximation, scales much better to high-dimensional datasets, and avoids OOD sampling.
\item We formally prove that DALE is an unbiased estimator of ALE and quantify the standard error of the approximation.
\item We experiment with synthetic and real datasets, showing that DALE: (a) scales in all cases better than ALE, (b) provides a better approximation compared to ALE, especially in cases of wide bin sizes
\end{itemize}
